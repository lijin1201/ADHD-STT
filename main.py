from fastapi import FastAPI, WebSocket
from fastapi.responses import HTMLResponse
import whisper
import os

app = FastAPI()

# Whisper base ëª¨ë¸ ë¡œë“œ (GPU ì‚¬ìš©)
model = whisper.load_model("base", device="cuda:0")

# ADHD ê°„ì´ ë¬¸í•­ (2ê°œ)
QUESTIONS = [
    "ë‹¹ì‹ ì€ ì£¼ì˜ê°€ ì‚°ë§Œí•˜ë‹¤ëŠ” ë§ì„ ìì£¼ ë“£ìŠµë‹ˆê¹Œ?",
    "ê°€ë§Œíˆ ì•‰ì•„ ìˆëŠ” ê²ƒì´ ì–´ë µë‹¤ê³  ëŠë¼ë‚˜ìš”?"
]

@app.get("/")
def home():
    return HTMLResponse("""
    <html>
    <head>
      <title>ADHD ìŒì„± ì§„ë‹¨</title>
    </head>
    <body>
      <h2><b>ADHD</b> ìŒì„± ì§„ë‹¨ í…ŒìŠ¤íŠ¸ (2ë¬¸í•­)</h2>
      <button onclick="startWebSocket()">ì§„ë‹¨ ì‹œì‘</button>
      <div id="messages"></div>
      <div id="status" style="margin-top: 10px; font-weight: bold; color: darkred;"></div>

      <script>
        let socket;
        let mediaRecorder;
        let audioChunks = [];
        
        function startWebSocket() {
          const host = window.location.host;
          socket = new WebSocket(`ws://${host}/ws/adhd-short`);
        
          socket.onmessage = async function(event) {
            const msg = event.data;
            const messagesDiv = document.getElementById("messages");
            const statusDiv = document.getElementById("status");
        
            const message = document.createElement("p");
            message.textContent = msg;
            messagesDiv.appendChild(message);
        
            if (msg.trim().startsWith("ë¬¸í•­")) {
              statusDiv.textContent = "ğŸ™ï¸ ë…¹ìŒ ì¤‘ì…ë‹ˆë‹¤... ì‘ë‹µì„ ë§ì”€í•´ ì£¼ì„¸ìš”.";
        
              // ë§ˆì´í¬ ë…¹ìŒ ì‹œì‘
              const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
              audioChunks = [];
              mediaRecorder = new MediaRecorder(stream);
        
              mediaRecorder.ondataavailable = e => {
                audioChunks.push(e.data);
              };
        
              mediaRecorder.onstop = async () => {
                const audioBlob = new Blob(audioChunks, { type: "audio/wav" });
                const arrayBuffer = await audioBlob.arrayBuffer();
                socket.send(arrayBuffer);
              };
        
              mediaRecorder.start();
        
              // 3ì´ˆ ë’¤ ìë™ ì¢…ë£Œ ë° ì „ì†¡
              setTimeout(() => {
                mediaRecorder.stop();
              }, 3000);
            }
        
            if (
              msg.trim().startsWith("ì¸ì‹ëœ ì‘ë‹µ") ||
              msg.includes("ì§„ë‹¨ì„ ì‹œì‘í•©ë‹ˆë‹¤") ||
              msg.includes("ì™„ë£Œ")
            ) {
              statusDiv.textContent = "";
            }
          };
        
          socket.onclose = function() {
            const message = document.createElement("p");
            message.textContent = "ì§„ë‹¨ì´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.";
            document.getElementById("messages").appendChild(message);
            document.getElementById("status").textContent = "";
          };
        }
      </script>
    </body>
    </html>
    """)

@app.websocket("/ws/adhd-short")
async def adhd_short(websocket: WebSocket):
    await websocket.accept()
    await websocket.send_text("ì§„ë‹¨ì„ ì‹œì‘í•©ë‹ˆë‹¤. ë§ˆì´í¬ë¡œ ì‘ë‹µì„ ë…¹ìŒí•´ ì£¼ì„¸ìš”.")

    for i, question in enumerate(QUESTIONS):
        await websocket.send_text(f"ë¬¸í•­ {i+1}: {question}")

        # í´ë¼ì´ì–¸íŠ¸ë¡œë¶€í„° ìŒì„± ë°ì´í„° ìˆ˜ì‹  (.wav í˜•ì‹)
        audio_bytes = await websocket.receive_bytes()
        audio_path = f"temp_question_{i}.wav"
        with open(audio_path, "wb") as f:
            f.write(audio_bytes)

        # Whisperë¥¼ í†µí•´ STT ìˆ˜í–‰
        result = model.transcribe(audio_path, language="ko")
        transcript = result["text"].strip()

        # ì‘ë‹µ ë°˜í™˜
        await websocket.send_text(f"ì¸ì‹ëœ ì‘ë‹µ: {transcript}")

        # ì„ì‹œ íŒŒì¼ ì‚­ì œ
        os.remove(audio_path)

    await websocket.send_text("ì§„ë‹¨ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ê°ì‚¬í•©ë‹ˆë‹¤.")
    await websocket.close()